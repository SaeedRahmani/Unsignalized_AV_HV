{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88cb9cb-d486-406e-9386-985f84b5482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\github\\lyft_intersection\\l5kit\\l5kit\\l5kit\\dataset\\select_agents.py:31: UserWarning: Windows detected. BLOSC_NOLOCK has not been set as it causes memory leaks on Windows.However, writing the mask with this config may be inconsistent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import PIL\n",
    "import imageio\n",
    "\n",
    "# load the configuration file\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.configs.config import load_metadata\n",
    "# load the dataset from zarr\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "# load the Ego/Agent-based dataset\n",
    "from l5kit.dataset import EgoDataset, AgentDataset, IntersectionDataset\n",
    "# define the road_network protobuf data structure\n",
    "from l5kit.data.proto.road_network_pb2 import RoadNetworkNode, RoadNetworkSegment\n",
    "# Semantic map api\n",
    "from l5kit.data.map_api import MapAPI\n",
    "# rasterizer\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "# geometry\n",
    "from l5kit.geometry import transform_points\n",
    "# trajectory\n",
    "from l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "223201f1-14dc-4f6a-b22f-2b0fb2f89616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'format_version': 4, 'model_params': {'model_architecture': 'resnet50', 'history_num_frames': 0, 'future_num_frames': 50, 'step_time': 0.1, 'render_ego_history': True}, 'raster_params': {'raster_size': [800, 800], 'pixel_size': [0.5, 0.5], 'ego_center': [0.5, 0.5], 'map_type': 'py_satellite', 'satellite_map_key': 'aerial_map/aerial_map.png', 'semantic_map_key': 'semantic_map/semantic_map.pb', 'dataset_meta_key': 'meta.json', 'filter_agents_threshold': 0.5, 'disable_traffic_light_faces': False, 'set_origin_to_bottom': True}, 'val_data_loader': {'key': 'scenes-train_full/train_full.zarr', 'batch_size': 12, 'shuffle': False, 'num_workers': 16}}\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   134622   |  33437057  | 2655096629 |   314473872   |      928.68     |        248.38        |        79.41         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "# load the configuration file\n",
    "cfg = load_config_data(\"../yaml_config/visualisation_config_train2.yaml\")\n",
    "print(cfg)\n",
    "\n",
    "# load the dataset from zarr\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"../\" ## Set the environmental variable\n",
    "dm = LocalDataManager()\n",
    "dataset_path = dm.require(cfg[\"val_data_loader\"][\"key\"])\n",
    "# print(dataset_path) # scenes\\sample.zarr\n",
    "zarr_dataset = ChunkedDataset(dataset_path)\n",
    "zarr_dataset.open()\n",
    "print(zarr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d81c9e3-4d65-4eef-8692-7ac6359b81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the rasterizer and dataset\n",
    "\n",
    "cfg[\"raster_params\"][\"map_type\"] = \"intersection\" # \"py_satellite\" # \"py_semantic\"   \n",
    "intersection_rast = build_rasterizer(cfg, dm)\n",
    "intersection_dataset = IntersectionDataset(cfg, zarr_dataset, intersection_rast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc264be8-89de-4680-a544-870f672fd7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#frames in the scenes-train_full/train_full.zarr: 33437057\n",
      "#scenes in the scenes-train_full/train_full.zarr: 134622\n"
     ]
    }
   ],
   "source": [
    "print(f\"#frames in the {cfg['val_data_loader']['key']}: {len(intersection_dataset)}\")\n",
    "print(f\"#scenes in the {cfg['val_data_loader']['key']}: {len(intersection_dataset.cumulative_sizes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3cb11e3-c30b-4890-b601-d9613f46837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb65cbdf1614fd2aacec395535c0b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134622 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\github\\lyft_intersection\\l5kit\\l5kit\\l5kit\\data\\zarr_dataset.py:213: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  dataset = ChunkedDataset(\"\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m scene \u001b[38;5;241m=\u001b[39m intersection_dataset\u001b[38;5;241m.\u001b[39mget_scene_dataset(scene_index\u001b[38;5;241m=\u001b[39mscene_index)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scene)):\n\u001b[1;32m---> 10\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mscene\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscene_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_intersection_included\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     12\u001b[0m         scenes_including_intersection\u001b[38;5;241m.\u001b[39mappend(scene_index)\n",
      "File \u001b[1;32mD:\\github\\lyft_intersection\\l5kit\\l5kit\\l5kit\\dataset\\intersection.py:144\u001b[0m, in \u001b[0;36mIntersectionDataset.get_frame\u001b[1;34m(self, scene_index, state_index, track_id)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# add information only, so that all data keys are always preserved\u001b[39;00m\n\u001b[0;32m    143\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscene_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m scene_index\n\u001b[1;32m--> 144\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(\u001b[43mconvert_str_to_fixed_length_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscenes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscene_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[0;32m    145\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m frames[state_index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    146\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint64(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m track_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m track_id)  \u001b[38;5;66;03m# always a number to avoid crashing torch\u001b[39;00m\n",
      "File \u001b[1;32mD:\\github\\lyft_intersection\\l5kit\\l5kit\\l5kit\\dataset\\utils.py:33\u001b[0m, in \u001b[0;36mconvert_str_to_fixed_length_tensor\u001b[1;34m(string, max_length)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mlen\u001b[39m(string) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_length\n\u001b[0;32m     28\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered string longer that maximum length supported (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\0\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mString contains 0 value used for padding: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m     31\u001b[0m     (\n\u001b[0;32m     32\u001b[0m         torch\u001b[38;5;241m.\u001b[39mByteTensor(torch\u001b[38;5;241m.\u001b[39mByteStorage\u001b[38;5;241m.\u001b[39mfrom_buffer(string\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m))),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     34\u001b[0m     )\n\u001b[0;32m     35\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# frames_including_intersection = []\n",
    "scenes_including_intersection = []\n",
    "\n",
    "for scene_index in tqdm(\n",
    "    range(len(intersection_dataset.cumulative_sizes)),\n",
    "    total=len(intersection_dataset.cumulative_sizes),\n",
    "    ):\n",
    "    scene = intersection_dataset.get_scene_dataset(scene_index=scene_index)\n",
    "    for frame_index in range(len(scene)):\n",
    "        frame = scene.get_frame(scene_index=0, state_index=frame_index)\n",
    "        if frame[\"is_intersection_included\"]:\n",
    "            scenes_including_intersection.append(scene_index)\n",
    "            break\n",
    "\n",
    "len(scenes_including_intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b97a061-f213-49be-9a10-690e05d24f8f",
   "metadata": {},
   "source": [
    "```python\n",
    "# keys in a frame:\n",
    "\n",
    "dict_keys(['frame_index', 'image', 'target_positions', 'target_yaws', 'target_velocities', 'target_availabilities', \n",
    "        'history_positions', 'history_yaws', 'history_velocities', 'history_availabilities', \n",
    "        'world_to_image', 'raster_from_agent', 'raster_from_world', 'agent_from_world', 'world_from_agent', \n",
    "        'centroid', 'yaw', 'extent', 'history_extents', 'future_extents', 'scene_index', \n",
    "        'host_id', 'timestamp', 'track_id', 'is_intersection_included'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee04416-c4b7-4ec5-9958-c0f3245dd3e6",
   "metadata": {},
   "source": [
    "Iterate the dataset to get all the frames that include the intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b90b69d-8db9-4726-9a54-6592267e176d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91915865b1924a2d973759644328a65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Identify the intersection of interest inside scenes-train_full/train_full.zarr::   0%|          | 0/33437057 […"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames_including_intersection = []\n",
    "scenes_including_intersection = []\n",
    "\n",
    "for idx, frame in tqdm(enumerate(intersection_dataset), \n",
    "                       total=len(intersection_dataset), \n",
    "                       unit=\"frame\",\n",
    "                       desc=f\"Identify the intersection of interest inside {cfg['val_data_loader']['key']}:\"):\n",
    "    if frame[\"is_intersection_included\"]:\n",
    "        # save the frame_id\n",
    "        frames_including_intersection.append(idx)\n",
    "        # FIXME: save the scene_id\n",
    "        scenes_including_intersection.append(frame[\"scene_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94a4cf7a-1c7f-49fa-ae1f-a176ff952454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6173562, 29140)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(frames_including_intersection)), len(set(scenes_including_intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50c44e55-4ca2-43aa-b982-8575ec6843f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#scenes including the intersection:\n",
      "29140\n"
     ]
    }
   ],
   "source": [
    "print(f\"#scenes including the intersection:\\n{len(set(scenes_including_intersection))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18ecf053-2345-44c8-b535-69214da91398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# TODO: save the ids in picked files:\n",
    "with open(\"../pickle_backup/intersection_identification/train2_scenes_including_intersection_v2.pkl\", 'wb') as file:\n",
    "    pickle.dump(set(scenes_including_intersection), file)\n",
    "\n",
    "with open(\"../pickle_backup/intersection_identification/train2_frames_including_intersection_v2.pkl\", 'wb') as file:\n",
    "    pickle.dump(set(frames_including_intersection), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcfd9bc-f565-4ca5-80b5-7b1d2a35b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./train2_scenes_including_intersection.pkl\", 'rb') as file:\n",
    "    set_scenes_including_intersection = pickle.load(file)\n",
    "\n",
    "list_scenes_including_intersection = list(set_scenes_including_intersection)\n",
    "\n",
    "with open(\"./train2_frames_including_intersection.pkl\", 'rb') as file:\n",
    "    set_frames_including_intersection = pickle.load(file)\n",
    "\n",
    "list_frames_including_intersection = list(set_frames_including_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f7138fc-586e-4d91-a98f-490f41f8bdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5511"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_scenes_including_intersection2 = np.array(list_scenes_including_intersection[1:])\n",
    "list_scenes_including_intersection1 = np.array(list_scenes_including_intersection[:-1])\n",
    "\n",
    "diff = list_scenes_including_intersection2 - list_scenes_including_intersection1\n",
    "np.sum(diff == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a94c5-2681-44d7-850d-dba2d721ebcc",
   "metadata": {},
   "source": [
    "## Visualization / Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a733a-9382-4ea6-af9a-bd8a61ee0f5f",
   "metadata": {},
   "source": [
    "Use GIF animation to check whether the frame includes the intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159f440-35c3-401a-9e4b-92c7c8030ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import PIL\n",
    " \n",
    "cfg[\"raster_params\"][\"map_type\"] = \"py_satellite\"\n",
    "rast = build_rasterizer(cfg, dm)\n",
    "dataset = EgoDataset(cfg, zarr_dataset, rast)\n",
    "scene_idx = 56\n",
    "indexes = dataset.get_scene_indices(scene_idx)\n",
    "images = [] # to store the frame for GIF\n",
    "\n",
    "for idx in indexes:\n",
    "    \n",
    "    data = dataset[idx]\n",
    "    im = data[\"image\"].transpose(1, 2, 0)\n",
    "    im = dataset.rasterizer.to_rgb(im)\n",
    "    target_positions_pixels = transform_points(data[\"target_positions\"], data[\"raster_from_agent\"])\n",
    "    center_in_pixels = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n",
    "    # draw_trajectory(im, target_positions_pixels, TARGET_POINTS_COLOR, yaws=data[\"target_yaws\"])\n",
    "    clear_output(wait=True)\n",
    "    display(PIL.Image.fromarray(im))\n",
    "\n",
    "    pil_image = PIL.Image.fromarray(im)\n",
    "    images.append(pil_image)\n",
    "\n",
    "imageio.mimsave(f\"./scene_gif/scene_{scene_idx}.gif\", images)\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fab97-b2b5-4005-bf3b-80b2119c436a",
   "metadata": {},
   "source": [
    "Use satellite map to check whether the frame includes the intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c8825-1ecb-42b6-9602-6e22be232d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameIndex = 23120\n",
    "cfg[\"raster_params\"][\"map_type\"] = \"py_satellite\" # \"intersection\" # \"py_semantic\"   \n",
    "rast = build_rasterizer(cfg, dm)\n",
    "dataset = IntersectionDataset(cfg, zarr_dataset, rast)\n",
    "data = dataset[frameIndex]\n",
    "\n",
    "im = data[\"image\"].transpose(1, 2, 0) # (224, 224, 5)\n",
    "im = dataset.rasterizer.to_rgb(im) # (224, 224, 3)\n",
    "target_positions_pixels = transform_points(data[\"target_positions\"], data[\"raster_from_agent\"])\n",
    "# draw_trajectory(im, target_positions_pixels, TARGET_POINTS_COLOR, yaws=data[\"target_yaws\"])\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1eec78-d884-4342-bf31-08b7a5e471b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
